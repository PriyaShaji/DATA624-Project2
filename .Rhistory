knitr::opts_chunk$set(echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align="center")
# Required R packages
library(tidyverse)
library(kableExtra)
library(psych)
library(caret)
library(mice)
library(corrplot)
library(xgboost)
install.packages("xgboost")
knitr::opts_chunk$set(echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align="center")
# Required R packages
library(tidyverse)
library(kableExtra)
library(psych)
library(caret)
library(mice)
library(corrplot)
library(xgboost)
library(Cubist)
# Set master seed
set.seed(52508)
# Set filepaths for data ingestion
urlRemote  = "https://github.com/"
pathGithub = "greeneyefirefly/DATA624-Project2/blob/main/"
fileTrain = "StudentData.xlsx"
fileTest = "StudentEvaluation.xlsx"
# Read training file
tempfile_1 = tempfile(fileext = ".xlsx")
tempfile_2 = tempfile(fileext = ".xlsx")
# Load training dataset
download.file(url = paste0(urlRemote, pathGithub, fileTrain, "?raw=true"),
destfile = tempfile_1,
mode = "wb",
quiet = TRUE)
train_df = data.frame(readxl::read_excel(tempfile_1,skip=0))
# Load test dataset
download.file(url =  paste0(urlRemote, pathGithub, fileTest, "?raw=true"),
destfile = tempfile_2,
mode = "wb",
quiet = TRUE)
eval_df = data.frame(readxl::read_excel(tempfile_2,skip=0))
# Number of training observations
ntrobs = dim(train_df)[[1]]
# Transform Brand.Code to factor
train_df$Brand.Code = as.factor(train_df$Brand.Code)
eval_df$Brand.Code = as.factor(eval_df$Brand.Code)
kable(describe(train_df)[,-c(1,6,7,13)],
caption = "Descriptive Statistics for All Brand Code",
digit = 2L)
na.counts = as.data.frame(((sapply(train_df, function(x) sum(is.na(x))))/nrow(train_df))*100)
names(na.counts) = "counts"
na.counts = cbind(variables = rownames(na.counts), data.frame(na.counts, row.names = NULL))
na.counts %>% arrange(counts) %>% mutate(name = factor(variables, levels = variables)) %>%
ggplot(aes(x = name, y = counts)) + geom_segment( aes(xend = name, yend = 0)) +
geom_point(size = 4, color = "steelblue2") + coord_flip() + theme_bw() +
labs(title = "Proportion of Missing Data", x = "Variables", y = "% of Missing data") +
scale_y_continuous(labels = scales::percent_format(scale = 1))
temp = data.frame(variables = NA, outlier = NA)
for (i in 2:33){
temp = rbind(temp, c(names(train_df)[i],
length(boxplot(train_df[i], plot = FALSE)$out)))
}
remove = apply(temp, 1, function(row) all(row !=0 ))
temp = na.omit(temp[remove,])
row.names(temp) = NULL
kable(temp, caption = "Predictive Variables with Outlier")
ggplot(data = reshape2::melt(train_df) , aes(x = variable, y = value)) +
geom_boxplot(fill = 'deeppink4') +
labs(title = 'Boxplot: Scaled Training Set',
x = 'Variables',
y = 'Normalized Values')+
theme(panel.background = element_rect(fill = 'grey'),
axis.text.x = element_text(size = 10, angle = 90))
corrplot::corrplot(cor(train_df[,-1], use = 'complete.obs'),
method = 'ellipse', type = 'lower', order = 'hclust',
hclust.method = 'ward.D2', tl.cex = 0.7)
corr = cor(train_df[,-1], use = 'complete.obs')
corr[corr == 1] = NA
corr[abs(corr) < 0.90] = NA
corr = na.omit(reshape::melt(corr))
kable(head(corr[order(-abs(corr$value)),], 10),
caption = "Top 10 Highly Correlated Predictor Candidates")
train_df %>%
ggplot(aes(PH, fill = PH > 8.75)) +
geom_histogram(bins = 30) +
theme_bw() +
theme(legend.position = 'center') +
labs(y = 'Count', title = 'pH Levels in Dataset')
# Train set
processed_train_df = mice(train_df, method = 'pmm', print = FALSE)
train_df_cleaned = complete(processed_train_df)
predictors = nearZeroVar(train_df_cleaned)
train_df_cleaned = train_df_cleaned[,-predictors]
# Evaluation set
processed_eval_df = mice(eval_df, method = 'pmm', print = FALSE)
eval_df_cleaned = complete(processed_eval_df)
predictors = nearZeroVar(eval_df_cleaned)
eval_df_cleaned = eval_df_cleaned[,-predictors]
# Train set
tooHigh = findCorrelation(cor(train_df_cleaned[,-1]), 0.90)
train_df_cleaned = train_df_cleaned[, -tooHigh]
# Evaluation set
tooHigh = findCorrelation(cor(eval_df_cleaned[,-1]), 0.90)
eval_df_cleaned = eval_df_cleaned[, -tooHigh]
# Train set
processed_train_df = preProcess(train_df_cleaned[,-1], method = c("YeoJohnson"))
train_df_cleaned[,-1] =  predict(processed_train_df, train_df_cleaned[,-1])
# Evaluation set
processed_eval_df = preProcess(eval_df_cleaned[,-1], method = c("YeoJohnson"))
eval_df_cleaned[,-1] =  predict(processed_eval_df, eval_df_cleaned[,-1])
# Create training and testing split from training data
set.seed(525)
intrain = createDataPartition(train_df_cleaned$PH, p = 0.70, list = FALSE)
# Train & Test predictor variables
train.p = train_df_cleaned[intrain, ] %>% select(-PH)
test.p = train_df_cleaned[-intrain, ] %>% select(-PH)
# Train & Test response variable (pH)
train.r = train_df_cleaned$PH[intrain]
test.r = train_df_cleaned$PH[-intrain]
# Baseline linear model
baseline = lm(train.r ~ ., data = train.p)
kable(summary(baseline)$coefficients, digits = 3L,
caption = 'Model 1 - Baseline Linear Regression Output')
set.seed(525)
marsGrid = expand.grid(.degree = 1:2,
.nprune = 2:38)
marsModel = train(x = train.p,
y = train.r,
method = "earth",
tuneGrid = marsGrid,
trControl = trainControl(method = "cv",
number = 10))
plot(marsModel, main = "RMSE of MARS Model")
set.seed(525)
cubModel = train(x = train.p,
y = train.r,
method = "cubist",
tuneLength = 10,
trControl = trainControl(method = "cv",
repeats = 5))
plot(cubModel, main = "RMSE of Cubist Tree Model")
set.seed(525)
marsPred = predict(marsModel, newdata = test.p)
cubPred = predict(cubModel , newdata = test.p)
compTable = data.frame(rbind(MARS = postResample(pred = marsPred, obs = test.r),
CUBIST = postResample(pred = cubPred, obs = test.r)))
kable(compTable, caption = "Performance Metric for All Models")
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
plot(plsModel, main = "RMSE of PLS Model")
set.seed(393)
plsModel = train(x = train.p,
y = train.r,
method = "pls",
metric="rmse",
tuneLength = 20,
trControl(method="cv"),
preProcess=c('center','scale'))
set.seed(393)
plsModel = train(x = train.p,
y = train.r,
method = "pls",
metric="rmse",
tuneLength = 20,
trControl= trainControl(method="cv"),
preProcess=c('center','scale'))
plot(plsModel, main = "RMSE of PLS Model")
set.seed(20350)
grid <- expand.grid(n.trees=c(50, 100, 150, 200),
interaction.depth=c(1, 5, 10, 15),
shrinkage=c(0.01, 0.1, 0.5),
n.minobsinnode=c(5, 10, 15))
gbm_m <- train(x = train.p,y = train.r, method = 'gbm',tuneGrid = grid, verbose = FALSE)
gbm_m$bestTune
set.seed(525)
marsPred = predict(marsModel, newdata = test.p)
cubPred = predict(cubModel , newdata = test.p)
plsPred = predict(plsModel, newdata= test.p)
gradPred = predict(gbm_m, newdata = test.p)
compTable = data.frame(rbind(MARS = postResample(pred = marsPred, obs = test.r),
CUBIST = postResample(pred = cubPred, obs = test.r),
PLS = postResample(pred = plsPred, obs= test.r),
GRADIENT_BOOSTING = postResample(pred= gradPred, obs=test.r)))
kable(compTable, caption = "Performance Metric for All Models")
View(train.p)
plot(gbm_m, main = "RMSE of Gradient Boosting Model")
plot(plsModel, main = "RMSE of PLS Model")
plot(gbm_m$bestTune, main = "RMSE of Gradient Boosting Model")
plot(gbm_m$finalModel, main = "RMSE of Gradient Boosting Model")
plot(gbm_m, main = "RMSE of Gradient Boosting Model")
set.seed(9988)
svmModel <- train(x = train.p,y = train.r,
method="svmRadial",
tuneLength = 10,
preProc=c("center","scale"))
svmModel <- train(x = train.p,y = train.r,
method="svmRadial",
tuneLength = 10,
preProc=c("center","scale"))
View(test.p)
View(train.p)
set.seed(9988)
rfModel <- train(x = train.p,y = train.r,
method='rf', tuneLength=10)
set.seed(9988)
rfModel <- train(x = train.p,y = train.r,
method='rf', tuneLength=4)
plot(rfModel, main = "RMSE of SVM Model")
set.seed(525)
marsPred = predict(marsModel, newdata = test.p)
cubPred = predict(cubModel , newdata = test.p)
plsPred = predict(plsModel, newdata= test.p)
gradPred = predict(gbm_m, newdata = test.p)
rfPred = predict(rfModel, newdata= test.p)
compTable = data.frame(rbind(MARS = postResample(pred = marsPred, obs = test.r),
CUBIST = postResample(pred = cubPred, obs = test.r),
PLS = postResample(pred = plsPred, obs= test.r),
GRADIENT_BOOSTING = postResample(pred= gradPred, obs=test.r).
set.seed(525)
marsPred = predict(marsModel, newdata = test.p)
cubPred = predict(cubModel , newdata = test.p)
plsPred = predict(plsModel, newdata= test.p)
gradPred = predict(gbm_m, newdata = test.p)
rfPred = predict(rfModel, newdata= test.p)
compTable = data.frame(rbind(MARS = postResample(pred = marsPred, obs = test.r),
CUBIST = postResample(pred = cubPred, obs = test.r),
PLS = postResample(pred = plsPred, obs= test.r),
GRADIENT_BOOSTING = postResample(pred= gradPred, obs=test.r),
Random_Forest = postResample(pred=rfPred, obs = test.r)))
kable(compTable, caption = "Performance Metric for All Models")
